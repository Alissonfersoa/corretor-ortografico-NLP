{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b37840a",
   "metadata": {},
   "source": [
    "# Corretor Ortográfico (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b177145",
   "metadata": {},
   "source": [
    "Desenvolvimento de um corretor ortográfico utilizando Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddf5bed",
   "metadata": {},
   "source": [
    "# 1. - Importar arquivo e leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852c33a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
      "\n",
      "java \n",
      "\n",
      "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
     ]
    }
   ],
   "source": [
    "# Abrindo o arquivo txt, armazenar seu conteúdo em uma variável declarada.\n",
    "\n",
    "with open('C:\\\\Users\\\\batis\\\\Documents\\\\Jupyter_Notebook\\\\treinamento.txt', encoding=\"utf8\",mode='r') as f:\n",
    "    treinamento = f.read()\n",
    "    \n",
    "# Lendo arquivo e imprimindo o conteúdo\n",
    "print(treinamento[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f459f7f4",
   "metadata": {},
   "source": [
    "Depois de fazer a leitura do arquivo temos que fazer a \"tokenização\" que é a separação do texto em \"tokens\".\n",
    "\n",
    "**Definição de Token:**\n",
    "    - Token é uma sequência de caracteres, separados por um limitador, que pode ser um espaço em branco, pontuação ou quebra de linhas, por exemplo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240b9ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2605046"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrando quantos caracteres possui o arquivo\n",
    "len(treinamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c94c8",
   "metadata": {},
   "source": [
    "# 2. - Fatiando o conteúdo do arquivo\n",
    "\n",
    "Utilizando o método _**split()**_ podemos identificar quantas palavras compoem o arquivo e não a quantidade de caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4845e94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Olá', 'Mundo!!', 'Terra', 'falando.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo da utilização do método\n",
    "exemplo_texto = 'Olá Mundo!! Terra falando.'\n",
    "\n",
    "# Tokenizando o texto com o split()\n",
    "tokens = exemplo_texto.split()\n",
    "\n",
    "# Imprimindo o resultado, ele separa as palavras pelo 'espaço' entre elas\n",
    "print(tokens)\n",
    "\n",
    "# Contando o tamanho da lista gerada\n",
    "len(tokens) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6db9a",
   "metadata": {},
   "source": [
    "**Import lib nltk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "180cc100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\batis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import lib e baixando o pacote punkt\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad1ad761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Olá', 'Mundo', '!', '!', 'Terra', 'falando', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizando o texto utilizando a lib nltk e mostrando o resultado\n",
    "\n",
    "palavras_separadas = nltk.tokenize.word_tokenize(exemplo_texto)\n",
    "print(palavras_separadas)\n",
    "len(palavras_separadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a617552",
   "metadata": {},
   "source": [
    "### Nota/Observação\n",
    "\n",
    "Notamos que ao utilizar a biblioteca nltk, é possível separar os caracteres (seja caractere especial ou pontuação) das palavras encontradas, porém ainda fazem parte de uma mesma lista."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20c426",
   "metadata": {},
   "source": [
    "# 2.1 - Separando os dados\n",
    "\n",
    "Para realizar a separação utilizo o método isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea98a9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/.'.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eed163d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ç'.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d245d77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'à'.isalpha()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb64125",
   "metadata": {},
   "source": [
    "### Nota/Observação\n",
    "Este método consiste em analisar e verificar se em uma sequência existe apenas letras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30b3aea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', 'Mundo', 'Terra', 'falando']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando uma função para separar as palavras\n",
    "def separa_palavras(lista_tokens):\n",
    "    \n",
    "    # Criando uma lista vázia\n",
    "    lista_palavras = []\n",
    "    \n",
    "    for token in lista_tokens:\n",
    "        \n",
    "        if token.isalpha():\n",
    "            \n",
    "            lista_palavras.append(token)\n",
    "    \n",
    "    return lista_palavras\n",
    "\n",
    "# Chamando a função e passando o parâmetro\n",
    "separa_palavras(palavras_separadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc50ebd6",
   "metadata": {},
   "source": [
    "Função criada, vamos para o próximo passo, criar o nosso corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a632c010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número total de palavras em nosso corpus é de : 403104\n"
     ]
    }
   ],
   "source": [
    "lista_tokens = nltk.tokenize.word_tokenize(treinamento)\n",
    "\n",
    "# Chamando a função e passando o corpus como parâmetro\n",
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "\n",
    "# Imprimindo o resultado\n",
    "print(f'O número total de palavras em nosso corpus é de : {len(lista_palavras)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76077ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'Temos', 'a', 'seguinte', 'classe']\n"
     ]
    }
   ],
   "source": [
    "# Amostragem dos resultados\n",
    "print(lista_palavras[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35228d64",
   "metadata": {},
   "source": [
    "# 3. - Normalização\n",
    "\n",
    "Normalizar as palavras é passar todas para um mesmo padrão, como por exemplo deixar todas em letras minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd2262e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no']\n"
     ]
    }
   ],
   "source": [
    "# Criando uma função de normalização utilizando o método lower()\n",
    "def normalizacao(lista_palavras):\n",
    "    \n",
    "    lista_normalizada = []\n",
    "    \n",
    "    for palavra in lista_palavras:\n",
    "        \n",
    "        lista_normalizada.append(palavra.lower())\n",
    "        \n",
    "    return lista_normalizada\n",
    "\n",
    "# Chamando a função e passando os parâmetros\n",
    "lista_normalizada = normalizacao(lista_palavras)\n",
    "\n",
    "# Imprimindo uma amostra do resultado\n",
    "print(lista_normalizada[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3370b942",
   "metadata": {},
   "source": [
    "### Nota/Observação\n",
    "Agora temos todas as palavras em letras minúsculas, facilitando a normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28071db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número total de palavras em nosso corpus é de: 18465\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo o total real de palavras existentes em nosso corpus\n",
    "print(f'O número total de palavras em nosso corpus é de: {len(set(lista_normalizada))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65378461",
   "metadata": {},
   "source": [
    "# 4. - Preparando estrutura do corretor\n",
    "Neste passo precisamos ensinar o nosso corretor a identificar erros e desvios de digitação para depois corrigí-los.\n",
    "\n",
    "A ideia é criar funções capazes de tratar cada tipo de erro identificados no conjunto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66458a9",
   "metadata": {},
   "source": [
    "# 4.1 - Tratativa do erro: Falta uma letra\n",
    "\n",
    "Para este caso vamos criar um exemplo, supondo que ao digitar a palavra **\"ortografia\"** sem querer enguli uma letra e saiu: **\"otografia\"**.\n",
    "\n",
    "Primeiro passo para corrigir e fatiar em duas partes a palavra no lugar exato e inserir a letra faltante entre a lacuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef288742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('o', 'tografia')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo\n",
    "\n",
    "exemplo_palavra = 'otografia'\n",
    "\n",
    "# Método slicing para fatiar uma string\n",
    "(exemplo_palavra[:1], exemplo_palavra[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67110792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o + \"a letra que falta (R)\" + tografia\n",
      "\n",
      "Resulta na palavra \n",
      "\n",
      "ortografia\n"
     ]
    }
   ],
   "source": [
    "# Exemplo da função para corrigir\n",
    "print(f'{exemplo_palavra[:1]} + \"a letra que falta (R)\" + {exemplo_palavra[1:]}'\n",
    "    f'\\n\\nResulta na palavra \\n\\n{exemplo_palavra[:1] + \"r\" + exemplo_palavra[1:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e7d675",
   "metadata": {},
   "source": [
    "Próximo passo é fazer isso para todas as palavras que estiverem faltando uma letra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b417c129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oatografia', 'obtografia', 'octografia', 'oetografia', 'odtografia']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando função para inserir as letras\n",
    "\n",
    "def insere_letras(fatias):\n",
    "    \n",
    "    novas_palavras =[]\n",
    "    \n",
    "    letras = 'abcedfghijklmnopqrstuvwxyzáâàãéêèíîìóôòõúûùç'\n",
    "    \n",
    "    for esquerdo, direito in fatias:\n",
    "        \n",
    "        for letra in letras:\n",
    "            \n",
    "            novas_palavras.append(esquerdo + letra + direito)\n",
    "    \n",
    "    return novas_palavras\n",
    "\n",
    "# Chamando a função e passando os parâmetros\n",
    "# Imprimindo uma amostra do resultado\n",
    "insere_letras([('o', 'tografia')])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "884c10c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aotografia', 'botografia', 'cotografia', 'eotografia', 'dotografia', 'fotografia', 'gotografia', 'hotografia', 'iotografia', 'jotografia']\n"
     ]
    }
   ],
   "source": [
    "# Função para gerar as palavras\n",
    "def gerador_palavras(palavra):\n",
    "    \n",
    "    fatias = []\n",
    "    \n",
    "    for i in range(len(palavra) + 1):\n",
    "        \n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    \n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    \n",
    "    return palavras_geradas\n",
    "\n",
    "palavras_geradas = gerador_palavras(exemplo_palavra)\n",
    "\n",
    "# Imprimindo a palavra de exemplo com uma amostra do resultado\n",
    "print(palavras_geradas[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e88da408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A palavra correta é \"ortografia\" e está dentro da lista gerada!\n"
     ]
    }
   ],
   "source": [
    "# Verifica se a palavra correta está dentro da lista gerada\n",
    "for palavra in palavras_geradas:\n",
    "    \n",
    "    if palavra == 'ortografia':\n",
    "        \n",
    "        print(f'A palavra correta é \"{palavra}\" e está dentro da lista gerada!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0078a79",
   "metadata": {},
   "source": [
    "Após a verificação o corretor precisa saber qual a palavra correta dentro da lista de palavras que foi gerado pela função\n",
    "\n",
    "Antes de seguir podemos ver a quantidade de palavras geradas anteriormente pela função com o método **len**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "453068f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foram geradas 440 palavras\n"
     ]
    }
   ],
   "source": [
    "print(f'Foram geradas {len(palavras_geradas)} palavras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce0ac9b",
   "metadata": {},
   "source": [
    "Para está etapa do corretor podemos usar a função **FreqDist()** da lib nltk.\n",
    "\n",
    "Esse método calcula a frequência que uma determinada palavra em um conjunto dentro do corpus.\n",
    "\n",
    "Utilizando esse método é preciso passar como input a palavra que desejamos saber a frequência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b184b69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 15502),\n",
       " ('o', 14056),\n",
       " ('que', 12230),\n",
       " ('a', 11099),\n",
       " ('e', 10501),\n",
       " ('para', 7710),\n",
       " ('um', 6368),\n",
       " ('é', 5899),\n",
       " ('uma', 5220),\n",
       " ('do', 5124)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chamando a função FreqDist\n",
    "# Passando como parânmetro de input a lista normalizada \n",
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "\n",
    "total_palavras = len(lista_normalizada)\n",
    "\n",
    "# Imprimindo as 10 palavras mais comuns dentro da lista\n",
    "frequencia.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc555064",
   "metadata": {},
   "source": [
    "### Nota/Observação\n",
    "Com este dado, podemos agora calcular a probabilidade de uma determinada palavra aparecer em nosso corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb77c239",
   "metadata": {},
   "source": [
    "Para isso, vamos criar uma função para cálculo da probabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6be5a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a função para probabilidade\n",
    "def probabilidade(palavra_gerada):\n",
    "    return frequencia[palavra_gerada] / total_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0bf1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função corretor\n",
    "def corretor(palavra_errada):\n",
    "    \n",
    "    palavras_geradas = gerador_palavras(palavra_errada)\n",
    "    \n",
    "    palavra_correta = max(palavras_geradas, key=probabilidade)\n",
    "    \n",
    "    # Retorna a palavra já corrigida\n",
    "    return palavra_correta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95edb3e2",
   "metadata": {},
   "source": [
    "Feito a criação das funções iniciais, vamos recriar o exemplo passando a palavra para corrigir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e501723c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ortografia'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Palavra incorreta\n",
    "exemplo_palavra = 'orografia'\n",
    "\n",
    "# Chamando a função do corretor\n",
    "corretor(exemplo_palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc1bbc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Você quis dizer: código\n"
     ]
    }
   ],
   "source": [
    "# Teste para a palavra lógica\n",
    "\n",
    "teste = 'cdigo'\n",
    "print(f'Você quis dizer: {corretor(teste)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d1da41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c0b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d20819d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ef5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4da753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1df5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee698b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dede73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4df127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4726a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e355c7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c93cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c9471c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b09d0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d630513d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d805cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8429776d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e91e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b212c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b36d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e414d4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
